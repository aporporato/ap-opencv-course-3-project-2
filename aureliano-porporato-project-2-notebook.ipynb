{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n\n#### Maximum Points: 100\n\n<div>\n    <table>\n        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n    </table>\n</div>","metadata":{"_uuid":"22b02bce-92f2-4a62-a2f0-4457910b0d67","_cell_guid":"65ba4d8f-3def-48bf-9a08-6a00df257363","trusted":true}},{"cell_type":"code","source":"!wget \"https://github.com/aporporato/ap-opencv-course-3-project-2/blob/main/trainer.zip?raw=true\" -O trainer.zip\n\n\nimport zipfile\n\nwith zipfile.ZipFile(\"./trainer.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\".\")\n    \n    \n!rm trainer.zip","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:03.664132Z","iopub.execute_input":"2022-01-01T01:12:03.664607Z","iopub.status.idle":"2022-01-01T01:12:06.871408Z","shell.execute_reply.started":"2022-01-01T01:12:03.664565Z","shell.execute_reply":"2022-01-01T01:12:06.870320Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:06.874519Z","iopub.execute_input":"2022-01-01T01:12:06.875053Z","iopub.status.idle":"2022-01-01T01:12:06.883099Z","shell.execute_reply.started":"2022-01-01T01:12:06.875003Z","shell.execute_reply":"2022-01-01T01:12:06.882267Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:06.884690Z","iopub.execute_input":"2022-01-01T01:12:06.884970Z","iopub.status.idle":"2022-01-01T01:12:06.894941Z","shell.execute_reply.started":"2022-01-01T01:12:06.884930Z","shell.execute_reply":"2022-01-01T01:12:06.894189Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport glob\n\nfrom typing import Iterable\nfrom dataclasses import dataclass\n\nfrom PIL import Image\n\nimport numpy as np\nfrom operator import itemgetter\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision.transforms import functional as FF\n\nfrom torchvision import datasets, transforms, models\n\nfrom torch.optim import lr_scheduler\nfrom torch.optim.lr_scheduler import MultiStepLR, ReduceLROnPlateau\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom trainer.trainer import Trainer\nfrom trainer.trainer_with_early_stopping import TrainerWithEarlyStopping\nimport trainer.hooks as hooks\nimport trainer.configuration as configuration\nfrom trainer.utils import setup_system, patch_configs\nfrom trainer.metrics import AccuracyEstimator\nfrom trainer.tensorboard_visualizer import TensorBoardVisualizer\n\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"2fa8f73c-4c8d-4388-a8a6-fefa8b8126eb","_cell_guid":"6f5cdd8d-392a-48d1-89c3-373a9ce7ec11","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-01T01:12:06.897624Z","iopub.execute_input":"2022-01-01T01:12:06.897912Z","iopub.status.idle":"2022-01-01T01:12:06.908469Z","shell.execute_reply.started":"2022-01-01T01:12:06.897873Z","shell.execute_reply":"2022-01-01T01:12:06.907605Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n\n%tensorboard --logdir=logs_ap_project_2","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:06.910089Z","iopub.execute_input":"2022-01-01T01:12:06.910643Z","iopub.status.idle":"2022-01-01T01:12:15.015617Z","shell.execute_reply.started":"2022-01-01T01:12:06.910605Z","shell.execute_reply":"2022-01-01T01:12:15.014767Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:15.017250Z","iopub.execute_input":"2022-01-01T01:12:15.017856Z","iopub.status.idle":"2022-01-01T01:12:15.022621Z","shell.execute_reply.started":"2022-01-01T01:12:15.017810Z","shell.execute_reply":"2022-01-01T01:12:15.021434Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"num_classes = 13\n\ndata_root = '/kaggle/input/opencv-pytorch-dl-course-classification'","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:15.023904Z","iopub.execute_input":"2022-01-01T01:12:15.024342Z","iopub.status.idle":"2022-01-01T01:12:15.033955Z","shell.execute_reply.started":"2022-01-01T01:12:15.024303Z","shell.execute_reply":"2022-01-01T01:12:15.032416Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n\nIn this section, you have to write a class or methods, which will be used to get training and validation data loader.\n\nYou need to write a custom dataset class to load data.\n\n**Note; There is   no separate validation data. , You will thus have to create your own validation set, by dividing the train data into train and validation data. Usually, we do 80:20 ratio for train and validation, respectively.**\n\n\nFor example:\n\n```python\nclass KenyanFood13Dataset(Dataset):\n    \"\"\"\n    \n    \"\"\"\n    \n    def __init__(self, *args):\n    ....\n    ...\n    \n    def __getitem__(self, idx):\n    ...\n    ...\n    \n    \n```\n\n```\ndef get_data(args1, *agrs):\n    ....\n    ....\n    return train_loader, test_loader\n```","metadata":{"_uuid":"da337382-dcaf-4a87-ab9c-41a54f99b77a","_cell_guid":"60ba61ad-e74a-4d8c-94d6-b48dba7b7370","trusted":true}},{"cell_type":"code","source":"class KenyanFood13Dataset(Dataset):\n    \"\"\"\n    Kenyan Food Dataset, from Kaggle, for the Project 2 of Deep Learning with Pytorch (by OpenCV.org)\n    \"\"\"\n    \n    def __init__(self, data_root, train=True, image_shape=None, transform=None):\n        \n        \"\"\"\n        init method of the class.\n        \n         Parameters:\n         \n         data_root (string): path of root directory.\n         \n         train (boolean): True for training dataset and False for test dataset.\n         \n         image_shape (int or tuple or list): [optional] int or tuple or list. Defaut is None. \n                                             It is not None image will resize to the given shape.\n                                 \n         transform (method): method that will take PIL image and transforms it.\n         \n        \"\"\"\n        \n        label_csv_path = os.path.join(data_root, 'train.csv')\n        \n        # load the data\n        self.dataset = pd.read_csv(label_csv_path, delimiter=' *, *', engine='python')\n        df_grouped = self.dataset.groupby('class')['id'].apply(list).to_dict()\n        self.classes = list(df_grouped.keys())\n        self.idx2class = {i: c for i, c in enumerate(self.classes)}\n        self.class2idx = {c: i for i, c in enumerate(self.classes)}\n        \n        \n        # set image_resize attribute\n        if image_shape is not None:\n            if isinstance(image_shape, int):\n                self.image_shape = (image_shape, image_shape)\n            \n            elif isinstance(image_shape, tuple) or isinstance(image_shape, list):\n                assert len(image_shape) == 1 or len(image_shape) == 2, 'Invalid image_shape tuple size'\n                if len(image_shape) == 1:\n                    self.image_shape = (image_shape[0], image_shape[0])\n                else:\n                    self.image_shape = image_shape\n            else:\n                raise NotImplementedError \n        else:\n            self.image_shape = None\n            \n        # set transform attribute\n        self.transform = transform\n                \n        self.num_classes = num_classes\n        \n        # initialize the data dictionary\n        self.data_dict = {\n            'image_path': [],\n            'label': []\n        }\n        \n        num_split = 0.9\n        cum_sum = 0\n        self.ex_classes = {}\n        path = os.path.join(data_root, 'images', 'images')\n        for label, values in df_grouped.items():\n            lim = int(len(values) * num_split)\n            self.ex_classes[label] = cum_sum\n            rang = range(lim) if train else range(lim, len(values))\n            for i in rang:\n                v = values[i]\n                img_path = os.path.join(path, '{}.jpg'.format(v))\n                self.data_dict['image_path'].append(img_path)\n                self.data_dict['label'].append(label)\n            cum_sum += len(rang)\n                    \n                \n    def __len__(self):\n        \"\"\"\n        Return length of the dataset\n        \"\"\"\n        \n        return len(self.data_dict['label'])\n    \n    \n    def __getitem__(self, idx):\n        \"\"\"\n        For given index, return images with resize and preprocessing.\n        \"\"\"\n        \n        image = Image.open(self.data_dict['image_path'][int(idx)]).convert(\"RGB\")\n        \n        if self.image_shape is not None:\n            image = FF.resize(image, self.image_shape)\n            \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        target = self.class2idx[self.data_dict['label'][int(idx)]]\n        \n        return image, target\n    \n    \n    def get_class_samples(self):\n        \"\"\"\n        Return a sample iamge for each class.\n        \"\"\"\n        \n        r = []\n        for l, i in self.ex_classes.items():\n            r.append((l, Image.open(self.data_dict['image_path'][i]).convert(\"RGB\")))\n        return r","metadata":{"_uuid":"621a8ed1-79c8-4a12-b433-ce44f7e98cae","_cell_guid":"413a626f-2782-45d1-856f-cb7fd98a286a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-01T01:12:15.036889Z","iopub.execute_input":"2022-01-01T01:12:15.037271Z","iopub.status.idle":"2022-01-01T01:12:15.059340Z","shell.execute_reply.started":"2022-01-01T01:12:15.037236Z","shell.execute_reply":"2022-01-01T01:12:15.058657Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"def image_preprocess_transforms():\n    \n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor()\n        ])\n    \n    return preprocess","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:15.061771Z","iopub.execute_input":"2022-01-01T01:12:15.062363Z","iopub.status.idle":"2022-01-01T01:12:15.069050Z","shell.execute_reply.started":"2022-01-01T01:12:15.062312Z","shell.execute_reply":"2022-01-01T01:12:15.068100Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"def image_common_transforms(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n    preprocess = image_preprocess_transforms()\n    \n    common_transforms = transforms.Compose([\n        preprocess,\n        transforms.Normalize(mean, std)\n    ])\n    \n    return common_transforms","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:15.073161Z","iopub.execute_input":"2022-01-01T01:12:15.073632Z","iopub.status.idle":"2022-01-01T01:12:15.081510Z","shell.execute_reply.started":"2022-01-01T01:12:15.073552Z","shell.execute_reply":"2022-01-01T01:12:15.080647Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"code","source":"def data_augmentation_preprocess(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=0.5, a=0.5):\n    preprocess = image_preprocess_transforms()\n    \n    augmentation_transforms = transforms.Compose([\n        preprocess,\n        # There are three groups of possible transformation, and two sub group for each of them:\n        #  - Orientation\n        #    - Horizontal Flop\n        #    - Random Affine\n        #  - Color\n        #    - Jitter\n        #    - Grayscale\n        #  - Erasure\n        #    - Random Crop\n        #    - Random Pad\n        #    - Random Erasing\n        #    - Gaussian Blur\n        # Each time every group is selected in random order, and then one of its subgroups at random is.\n        #  Then there is some probability (controlled by p) that those subgroup is applied;\n        #  If relevant, the amount of modification applied is controlled by a\n        transforms.RandomOrder([\n            # Orientation and Affine Augmentation\n            transforms.RandomChoice([\n                transforms.RandomHorizontalFlip(p),\n                transforms.RandomChoice([\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(0, translate=None, scale=None, shear=a)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(0, translate=None, scale=(1-a/4, 1+a/2), shear=None)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(0, translate=None, scale=(1-a/8, 1+a/4), shear=a/2)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(0, translate=(a/4, a/4), scale=None, shear=None)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(0, translate=(a/8, a/8), scale=None, shear=a/2)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(0, translate=(a/8, a/8), scale=(1-a/8, 1+a/4), shear=None)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(0, translate=(a/16, a/16), scale=(1-a/16, 1+a/8), shear=a/4)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(a*200, translate=None, scale=None, shear=None)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(a*100, translate=None, scale=None, shear=a/2)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(a*100, translate=None, scale=(1-a/8, 1+a/4), shear=None)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(a*50, translate=None, scale=(1-a/16, 1+a/8), shear=a/4)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(a*100, translate=(a/8, a/8), scale=None, shear=None)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(a*50, translate=(a/16, a/16), scale=None, shear=a/4)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(a*50, translate=(a/16, a/16), scale=(1-a/16, 1+a/8), shear=None)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.RandomAffine(a*25, translate=(a/32, a/32), scale=(1-a/32, 1+a/16), shear=a/8)]), p)\n                ])\n            ]),\n            # Color Augmentation\n            transforms.RandomChoice([\n                transforms.RandomChoice([\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=a/2)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=0, contrast=0, saturation=a, hue=0)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=0, contrast=0, saturation=a/2, hue=a/4)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=0, contrast=a, saturation=0, hue=0)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=0, contrast=a/2, saturation=0, hue=a/4)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=0, contrast=a/2, saturation=a/2, hue=0)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=0, contrast=a/4, saturation=a/4, hue=a/8)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=a, contrast=0, saturation=0, hue=0)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=a/2, contrast=0, saturation=0, hue=a/4)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=a/2, contrast=0, saturation=a/2, hue=0)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=a/4, contrast=0, saturation=a/4, hue=a/8)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=a/2, contrast=a/2, saturation=0, hue=0)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=a/4, contrast=a/4, saturation=0, hue=a/8)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=a/4, contrast=a/4, saturation=a/4, hue=0)]), p),\n                    transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(brightness=a/8, contrast=a/8, saturation=a/8, hue=a/16)]), p)\n                ]),\n                transforms.RandomGrayscale(p)\n            ]),\n            # Erasure Augmentation\n            transforms.RandomChoice([\n                transforms.RandomApply(nn.ModuleList([transforms.RandomCrop(224, pad_if_needed=True, fill=mean)]), p),\n                transforms.RandomApply(nn.ModuleList([transforms.Pad(int(a * 23) + 1), transforms.Resize(224)]), p),\n                transforms.RandomErasing(p, value=list(mean)),\n                transforms.RandomApply(nn.ModuleList([transforms.GaussianBlur(3)]), p)\n            ]),\n        ]),\n        transforms.Normalize(mean, std)\n    ])\n    \n    return augmentation_transforms","metadata":{"_uuid":"9e41600b-c8f6-4928-928e-e6004f66a205","_cell_guid":"78acef71-7a5e-4287-9858-e161da4053ac","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-01T01:12:15.084168Z","iopub.execute_input":"2022-01-01T01:12:15.084443Z","iopub.status.idle":"2022-01-01T01:12:15.121519Z","shell.execute_reply.started":"2022-01-01T01:12:15.084412Z","shell.execute_reply":"2022-01-01T01:12:15.120739Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"code","source":"def get_resnet_mean_std():\n    \n    mean = [0.485, 0.456, 0.406] \n    std = [0.229, 0.224, 0.225]\n    \n    return mean, std","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:15.122834Z","iopub.execute_input":"2022-01-01T01:12:15.123077Z","iopub.status.idle":"2022-01-01T01:12:15.129480Z","shell.execute_reply.started":"2022-01-01T01:12:15.123044Z","shell.execute_reply":"2022-01-01T01:12:15.128747Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":"def data_loader(data_root, train=True, transform=None, batch_size=16, shuffle=False, num_workers=2):\n    dataset = KenyanFood13Dataset(data_root, train=train, image_shape=None, transform=transform)\n    \n    loader = torch.utils.data.DataLoader(dataset, \n                                         batch_size=batch_size,\n                                         num_workers=num_workers,\n                                         shuffle=shuffle)\n    \n    return loader","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:15.131743Z","iopub.execute_input":"2022-01-01T01:12:15.132486Z","iopub.status.idle":"2022-01-01T01:12:15.139342Z","shell.execute_reply.started":"2022-01-01T01:12:15.132440Z","shell.execute_reply":"2022-01-01T01:12:15.138533Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"def get_data(batch_size, data_root, num_workers=2, data_augmentation=True):\n    \n    mean, std = get_resnet_mean_std()\n    \n    common_transforms = image_common_transforms(mean, std)\n   \n    # if data_augmentation is true \n    # data augmentation implementation\n    if data_augmentation:    \n        train_transforms = data_augmentation_preprocess(mean, std)\n    # else do common transforms\n    else:\n        train_transforms = common_transforms\n        \n    # train dataloader\n    train_loader = data_loader(data_root,\n                               train=True, \n                               transform=train_transforms, \n                               batch_size=batch_size, \n                               shuffle=True, \n                               num_workers=num_workers)\n    \n    # test dataloader\n    test_loader = data_loader(data_root,\n                              train=False, \n                              transform=common_transforms, \n                              batch_size=batch_size, \n                              shuffle=False, \n                              num_workers=num_workers)\n    \n    return train_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:15.140758Z","iopub.execute_input":"2022-01-01T01:12:15.141600Z","iopub.status.idle":"2022-01-01T01:12:15.149842Z","shell.execute_reply.started":"2022-01-01T01:12:15.141560Z","shell.execute_reply":"2022-01-01T01:12:15.149142Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"markdown","source":"### <font style=\"color:green\">1.1 Data and Training Pipeline Check</font>","metadata":{"_uuid":"42d89af7-dc7d-48b3-a73d-af4d16e69d2a","_cell_guid":"3879c55a-ca49-4b4f-916e-71b13dec2da0","trusted":true}},{"cell_type":"markdown","source":"#### <font style=\"color:green\">1.1.1 Data Exploration</font>","metadata":{"_uuid":"e8df9233-83a1-47b1-93c3-54767bc10a59","_cell_guid":"7827503b-c00c-4009-ba10-8722d1e9917f","trusted":true}},{"cell_type":"code","source":"train_data = KenyanFood13Dataset(data_root, train=True)\nvalidation_data = KenyanFood13Dataset(data_root, train=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:12:15.151247Z","iopub.execute_input":"2022-01-01T01:12:15.152066Z","iopub.status.idle":"2022-01-01T01:13:05.981186Z","shell.execute_reply.started":"2022-01-01T01:12:15.152026Z","shell.execute_reply":"2022-01-01T01:13:05.980399Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"idx2class = train_data.idx2class\nclass2idx = train_data.class2idx","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:05.982719Z","iopub.execute_input":"2022-01-01T01:13:05.982992Z","iopub.status.idle":"2022-01-01T01:13:05.987553Z","shell.execute_reply.started":"2022-01-01T01:13:05.982957Z","shell.execute_reply":"2022-01-01T01:13:05.986817Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"markdown","source":"Classes:","metadata":{}},{"cell_type":"code","source":"print(train_data.classes)\nprint(validation_data.classes)\nprint(idx2class)\nprint(class2idx)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:05.989055Z","iopub.execute_input":"2022-01-01T01:13:05.989570Z","iopub.status.idle":"2022-01-01T01:13:05.998519Z","shell.execute_reply.started":"2022-01-01T01:13:05.989533Z","shell.execute_reply":"2022-01-01T01:13:05.997632Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"markdown","source":"Number of samples:","metadata":{}},{"cell_type":"code","source":"print(\"Trainig Data:\", len(train_data))\nprint(\"Validation Data:\", len(validation_data))\nprint(\"Total:\", len(train_data) + len(validation_data))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:05.999984Z","iopub.execute_input":"2022-01-01T01:13:06.000952Z","iopub.status.idle":"2022-01-01T01:13:06.008888Z","shell.execute_reply.started":"2022-01-01T01:13:06.000909Z","shell.execute_reply":"2022-01-01T01:13:06.007848Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"markdown","source":"Show examples:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nfor i, (label, img) in enumerate(train_data.get_class_samples()):\n    plt.subplot(4, 4, i + 1)\n    plt.imshow(img)\n    plt.gca().set_title('Target: {0}'.format(label))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:06.010521Z","iopub.execute_input":"2022-01-01T01:13:06.011648Z","iopub.status.idle":"2022-01-01T01:13:09.286844Z","shell.execute_reply.started":"2022-01-01T01:13:06.011610Z","shell.execute_reply":"2022-01-01T01:13:09.285675Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"markdown","source":"#### <font style=\"color:green\">1.1.2 Check Data Preparation</font>\nGeneare a small dataset for pipline checking purposes.","metadata":{"_uuid":"2aab2c63-df56-4469-aa7c-49b5661c2cc1","_cell_guid":"0a8685bb-926b-4f20-8ae0-662168756c8f","trusted":true}},{"cell_type":"code","source":"subset_size = .1","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:09.288216Z","iopub.execute_input":"2022-01-01T01:13:09.288642Z","iopub.status.idle":"2022-01-01T01:13:09.291882Z","shell.execute_reply.started":"2022-01-01T01:13:09.288606Z","shell.execute_reply":"2022-01-01T01:13:09.291222Z"},"trusted":true},"execution_count":253,"outputs":[]},{"cell_type":"code","source":"def get_mean_std(data_root, num_workers=1, verbose=False):\n    \n    transform = image_preprocess_transforms()\n    \n    loader = data_loader(data_root, train=True, transform=transform, batch_size=8, shuffle=False, num_workers=num_workers)\n\n    mean = 0.\n    std = 0.\n    \n    for images, _ in loader:\n        batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n        images = images.view(batch_samples, images.size(1), -1)\n        mean += images.mean(2).sum(0)\n        std += images.std(2).sum(0)\n\n    mean /= len(loader.dataset)\n    std /= len(loader.dataset)\n    \n    if verbose:\n        print('mean: {}, std: {}'.format(mean, std))\n    \n    return mean, std","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:09.293176Z","iopub.execute_input":"2022-01-01T01:13:09.293610Z","iopub.status.idle":"2022-01-01T01:13:09.302706Z","shell.execute_reply.started":"2022-01-01T01:13:09.293575Z","shell.execute_reply":"2022-01-01T01:13:09.302019Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"code","source":"def subset_data_loader(data_root, train=True, transform=None, batch_size=8, shuffle=False, num_workers=1):\n    dataset = KenyanFood13Dataset(data_root, train=train, image_shape=256, transform=transform)\n    \n    data_subset = torch.utils.data.Subset(dataset, np.arange(0, len(dataset), 1./subset_size))\n    \n    loader = torch.utils.data.DataLoader(data_subset, \n                                         batch_size=batch_size,\n                                         num_workers=num_workers,\n                                         shuffle=shuffle)\n    \n    return loader","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:09.304134Z","iopub.execute_input":"2022-01-01T01:13:09.304655Z","iopub.status.idle":"2022-01-01T01:13:09.314405Z","shell.execute_reply.started":"2022-01-01T01:13:09.304611Z","shell.execute_reply":"2022-01-01T01:13:09.313494Z"},"trusted":true},"execution_count":255,"outputs":[]},{"cell_type":"code","source":"def get_check_data(batch_size, data_root=data_root, num_workers=1):\n    \n    # mean, std = get_mean_std(data_root, verbose=True)\n    mean, std = ([0.5778, 0.4629, 0.3459], [0.2380, 0.2463, 0.2467])\n    \n    show_transforms = image_preprocess_transforms()\n    train_test_transforms = image_common_transforms(mean, std)\n\n    # show dataloader\n    show_loader = subset_data_loader(data_root,\n                                      train=True, \n                                      transform=show_transforms, \n                                      batch_size=batch_size, \n                                      shuffle=True, \n                                      num_workers=num_workers)\n\n    # train dataloader\n    train_loader = subset_data_loader(data_root,\n                                      train=True, \n                                      transform=train_test_transforms, \n                                      batch_size=batch_size, \n                                      shuffle=True, \n                                      num_workers=num_workers)\n    \n    # test dataloader\n    test_loader = subset_data_loader(data_root,\n                                     train=False, \n                                     transform=train_test_transforms, \n                                     batch_size=batch_size, \n                                     shuffle=False, \n                                     num_workers=num_workers)\n    \n    return show_loader, train_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:09.315962Z","iopub.execute_input":"2022-01-01T01:13:09.316273Z","iopub.status.idle":"2022-01-01T01:13:09.325947Z","shell.execute_reply.started":"2022-01-01T01:13:09.316202Z","shell.execute_reply":"2022-01-01T01:13:09.325219Z"},"trusted":true},"execution_count":256,"outputs":[]},{"cell_type":"markdown","source":"Check data before they pass through the model (to avoid normalization issues, use the validation set).","metadata":{}},{"cell_type":"code","source":"show_subset, train_subset, _ = get_check_data(16)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:09.327277Z","iopub.execute_input":"2022-01-01T01:13:09.327736Z","iopub.status.idle":"2022-01-01T01:13:09.463743Z","shell.execute_reply.started":"2022-01-01T01:13:09.327702Z","shell.execute_reply":"2022-01-01T01:13:09.463067Z"},"trusted":true},"execution_count":257,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nfor images, labels in show_subset:\n    for i in range(len(labels)):\n        plt.subplot(4, 4, i+1)\n        img = transforms.functional.to_pil_image(images[i])\n        plt.imshow(img)\n        plt.gca().set_title('Target: {0}'.format(labels[i]))\n    plt.show()\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:09.465295Z","iopub.execute_input":"2022-01-01T01:13:09.465505Z","iopub.status.idle":"2022-01-01T01:13:13.274730Z","shell.execute_reply.started":"2022-01-01T01:13:09.465480Z","shell.execute_reply":"2022-01-01T01:13:13.273860Z"},"trusted":true},"execution_count":258,"outputs":[]},{"cell_type":"markdown","source":"#### <font style=\"color:green\">1.1.3 Check Configurations</font>","metadata":{"_uuid":"8e3acb12-e629-419e-ac47-c5f12155f03f","_cell_guid":"886b7add-e23e-4449-be03-4e4adb1aa756","trusted":true}},{"cell_type":"code","source":"check_system_config = configuration.SystemConfig(seed=41,\n                                                 cudnn_benchmark_enabled=True,\n                                                 cudnn_deterministic=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:13.276228Z","iopub.execute_input":"2022-01-01T01:13:13.276470Z","iopub.status.idle":"2022-01-01T01:13:13.281402Z","shell.execute_reply.started":"2022-01-01T01:13:13.276439Z","shell.execute_reply":"2022-01-01T01:13:13.280390Z"},"trusted":true},"execution_count":259,"outputs":[]},{"cell_type":"code","source":"mean, std = ([0.5778, 0.4629, 0.3459], [0.2380, 0.2463, 0.2467])\ntrain_validation_transforms = image_common_transforms(mean, std)\ncheck_dataset_config = configuration.DatasetConfig(root_dir=data_root,\n                                                   train_transforms=train_validation_transforms,\n                                                   test_transforms=train_validation_transforms)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:13.282888Z","iopub.execute_input":"2022-01-01T01:13:13.283463Z","iopub.status.idle":"2022-01-01T01:13:13.294481Z","shell.execute_reply.started":"2022-01-01T01:13:13.283424Z","shell.execute_reply":"2022-01-01T01:13:13.293662Z"},"trusted":true},"execution_count":260,"outputs":[]},{"cell_type":"code","source":"check_dataloader_config = configuration.DataloaderConfig(batch_size=16 if torch.cuda.is_available() else 8,\n                                                         num_workers=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:13.300720Z","iopub.execute_input":"2022-01-01T01:13:13.300931Z","iopub.status.idle":"2022-01-01T01:13:13.307115Z","shell.execute_reply.started":"2022-01-01T01:13:13.300888Z","shell.execute_reply":"2022-01-01T01:13:13.306401Z"},"trusted":true},"execution_count":261,"outputs":[]},{"cell_type":"code","source":"check_optimizer_config = configuration.OptimizerConfig(learning_rate=0.01,\n                                                       momentum=0.9,\n                                                       weight_decay=0.0001,\n                                                       lr_step_milestones=(18, 24),\n                                                       lr_gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:13.308504Z","iopub.execute_input":"2022-01-01T01:13:13.308716Z","iopub.status.idle":"2022-01-01T01:13:13.316123Z","shell.execute_reply.started":"2022-01-01T01:13:13.308690Z","shell.execute_reply":"2022-01-01T01:13:13.315055Z"},"trusted":true},"execution_count":262,"outputs":[]},{"cell_type":"code","source":"check_trainer_config = configuration.TrainerConfig(model_dir=\"check_checkpoints\",\n                                                   model_saving_frequency=2,\n                                                   device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n                                                   epoch_num=30,\n                                                   progress_bar=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:13.317870Z","iopub.execute_input":"2022-01-01T01:13:13.318218Z","iopub.status.idle":"2022-01-01T01:13:13.324261Z","shell.execute_reply.started":"2022-01-01T01:13:13.318177Z","shell.execute_reply":"2022-01-01T01:13:13.323428Z"},"trusted":true},"execution_count":263,"outputs":[]},{"cell_type":"markdown","source":"#### <font style=\"color:green\">1.1.4 Check Model Training and Validation</font>","metadata":{"_uuid":"1ecb34f9-423c-4886-9713-43434744565c","_cell_guid":"f659cd5b-4975-4752-a945-a34e1dfac6f1","trusted":true}},{"cell_type":"markdown","source":"##### <font style=\"color:green\">1.1.4.1 Check Model</font>\nShrunk version of AlexNet selected as model for pipeline checking","metadata":{}},{"cell_type":"code","source":"class ShrunkAlexNet(nn.Module):\n    def __init__(self, num_classes: int = 1000, dropout: float = 0.5) -> None:\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            \n            nn.Conv2d(32, 96, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            \n            nn.Conv2d(96, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(192, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            \n            nn.AdaptiveAvgPool2d((6, 6)),\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(p=dropout),\n            \n            nn.Linear(128 * 6 * 6, 2048),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(p=dropout),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            \n            nn.Linear(2048, num_classes)\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:13.325914Z","iopub.execute_input":"2022-01-01T01:13:13.326336Z","iopub.status.idle":"2022-01-01T01:13:13.340190Z","shell.execute_reply.started":"2022-01-01T01:13:13.326288Z","shell.execute_reply":"2022-01-01T01:13:13.339342Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"markdown","source":"##### <font style=\"color:green\">1.1.4.2 Initial Check</font>\n\nCheck if the intial loss is around `log(num_classes)` and the initial accuracy is around `1/num_classes`.","metadata":{}},{"cell_type":"code","source":"class CheckInitLossAndAccuracy():\n    def __init__(self, net, x, num_classes, target=None):\n        self.net = net\n        self.x = x\n        self.num_classes = num_classes\n        self.criterion = nn.CrossEntropyLoss()\n        self.batch_size = self.x.size()[0]\n        if target is None:\n            self.target = torch.randint(0, self.num_classes, size=(self.batch_size,))\n        else:\n            self.target = target\n        self.logits = self.net(self.x)\n\n    def verify_init_loss(self):\n        loss = self.criterion(self.logits, self.target)\n        print(\"Expected loss is \", np.log(self.num_classes))\n        print(\"Inferred loss is \", loss.item())\n        return None\n\n    def verify_init_accuracy(self):\n        predictions = torch.argmax(F.softmax(self.logits, dim=1), axis=1)\n        accuracy = accuracy_score(self.target, predictions.detach())\n        print(\"Expected accuracy is \", 1 / self.num_classes)\n        print(\"Inferred accuracy is \", accuracy)\n        return None","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:13.341882Z","iopub.execute_input":"2022-01-01T01:13:13.342193Z","iopub.status.idle":"2022-01-01T01:13:13.351491Z","shell.execute_reply.started":"2022-01-01T01:13:13.342157Z","shell.execute_reply":"2022-01-01T01:13:13.350713Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"code","source":"x, target = next(iter(train_subset))\n\nmodel = ShrunkAlexNet(num_classes)\ncheck = CheckInitLossAndAccuracy(model, x, num_classes, target)\ncheck.verify_init_loss()\ncheck.verify_init_accuracy()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:13.352880Z","iopub.execute_input":"2022-01-01T01:13:13.353355Z","iopub.status.idle":"2022-01-01T01:13:14.717175Z","shell.execute_reply.started":"2022-01-01T01:13:13.353316Z","shell.execute_reply":"2022-01-01T01:13:14.716307Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"markdown","source":"Check if loss decreases every epoch.","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.RMSprop(model.parameters(), lr=0.001, momentum=0.9)\n\nloss_list = []\nnum_epochs = 10\nfor epoch in range(num_epochs): \n    per_epoch_loss = 0\n    for i, data in enumerate(train_subset): \n        optimizer.zero_grad()\n        x, target = data\n        logits = model(x)\n        loss = criterion(logits, target)\n        temp_loss = loss.item()\n        per_epoch_loss+=temp_loss\n        loss.backward()\n        optimizer.step()\n        \n    per_epoch_avg_loss = per_epoch_loss/(i+1)\n    loss_list.append(per_epoch_avg_loss)\n    print(\"Loss at epoch {0} = {1}\".format(epoch + 1, per_epoch_avg_loss))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:13:14.718905Z","iopub.execute_input":"2022-01-01T01:13:14.719422Z","iopub.status.idle":"2022-01-01T01:17:06.479552Z","shell.execute_reply.started":"2022-01-01T01:13:14.719353Z","shell.execute_reply":"2022-01-01T01:17:06.478661Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6,4))\nplt.plot(loss_list)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.xticks(np.arange(0,10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:17:06.481340Z","iopub.execute_input":"2022-01-01T01:17:06.481935Z","iopub.status.idle":"2022-01-01T01:17:06.677916Z","shell.execute_reply.started":"2022-01-01T01:17:06.481889Z","shell.execute_reply":"2022-01-01T01:17:06.677209Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"markdown","source":"Forward the same batch for multiple interations and check if loss drops down to 0","metadata":{}},{"cell_type":"code","source":"model_overfit = ShrunkAlexNet(num_classes)\noptimizer = optim.Adam(model_overfit.parameters(), lr=0.001)\n\nx, target = next(iter(train_subset))\n\nloss_list = []\nnum_iters = 10\nfor i in range(num_iters): \n    optimizer.zero_grad()\n    logits = model_overfit(x)\n    loss = criterion(logits, target)\n    temp_loss = loss.item()\n    loss.backward()\n    optimizer.step()\n    loss_list.append(temp_loss)\n    print(\"Loss at iteration-{} is {}\".format(i+1,temp_loss))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:17:06.679032Z","iopub.execute_input":"2022-01-01T01:17:06.679285Z","iopub.status.idle":"2022-01-01T01:17:11.710733Z","shell.execute_reply.started":"2022-01-01T01:17:06.679248Z","shell.execute_reply":"2022-01-01T01:17:11.709717Z"},"trusted":true},"execution_count":269,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (6,4))\nplt.plot(loss_list)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.xticks(np.arange(0,i+1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:17:11.712494Z","iopub.execute_input":"2022-01-01T01:17:11.713442Z","iopub.status.idle":"2022-01-01T01:17:11.916955Z","shell.execute_reply.started":"2022-01-01T01:17:11.713393Z","shell.execute_reply":"2022-01-01T01:17:11.916220Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"markdown","source":"Forward-pass a zero input and check if loss is high.","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\nx = torch.zeros(size=(16, 3, 224, 224))\ntarget = torch.randint(0, num_classes, size=(16,))\nlogits = model(x)\n\nloss = criterion(logits,target)\nprint(\"Loss with zero-valued input is \", loss.item())","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:17:11.918056Z","iopub.execute_input":"2022-01-01T01:17:11.918308Z","iopub.status.idle":"2022-01-01T01:17:12.012995Z","shell.execute_reply.started":"2022-01-01T01:17:11.918270Z","shell.execute_reply":"2022-01-01T01:17:12.012107Z"},"trusted":true},"execution_count":271,"outputs":[]},{"cell_type":"markdown","source":"##### <font style=\"color:green\">1.1.4.3 Check Utils</font>","metadata":{}},{"cell_type":"code","source":"# Max-Norm Regularization for Dropout\n#  (from https://discuss.pytorch.org/t/how-to-correctly-implement-in-place-max-norm-constraint/96769 \n#    and https://github.com/kevinzakka/pytorch-goodies#max-norm-constraint )\ndef max_norm(model, max_val=10.0, eps=1e-8):\n    with torch.no_grad():\n        for param in model.parameters():\n            norm = param.norm(2, dim=0, keepdim=True).clamp(min=eps)\n            desired = torch.clamp(norm, max=max_val)\n            param *= (desired / norm)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:17:12.014208Z","iopub.execute_input":"2022-01-01T01:17:12.014489Z","iopub.status.idle":"2022-01-01T01:17:12.021217Z","shell.execute_reply.started":"2022-01-01T01:17:12.014450Z","shell.execute_reply":"2022-01-01T01:17:12.020259Z"},"trusted":true},"execution_count":272,"outputs":[]},{"cell_type":"markdown","source":"##### <font style=\"color:green\">1.1.4.4 Check Experiment</font>","metadata":{}},{"cell_type":"code","source":"class CheckExperiment:\n    def __init__(\n        self,\n        system_config: configuration.SystemConfig = configuration.SystemConfig(),\n        dataset_config: configuration.DatasetConfig = configuration.DatasetConfig(),\n        dataloader_config: configuration.DataloaderConfig = configuration.DataloaderConfig(),\n        optimizer_config: configuration.OptimizerConfig = configuration.OptimizerConfig()\n    ):\n        _, self.loader_train, self.loader_test = get_check_data(\n            batch_size=dataloader_config.batch_size,\n            data_root=dataset_config.root_dir,\n            num_workers=dataloader_config.num_workers\n        )\n        \n        setup_system(system_config)\n\n        self.model = ShrunkAlexNet(num_classes)\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.metric_fn = AccuracyEstimator(topk=(1, ))\n        # self.optimizer = optim.RAdam(\n        self.optimizer = optim.Adam(\n            self.model.parameters(),\n            lr=optimizer_config.learning_rate\n        )\n        self.lr_scheduler = ReduceLROnPlateau(\n            self.optimizer\n        )\n        self.visualizer = None\n\n    def run(self, trainer_config: configuration.TrainerConfig) -> dict:\n\n        device = torch.device(trainer_config.device)\n        self.model = self.model.to(device)\n        self.loss_fn = self.loss_fn.to(device)\n\n        model_trainer = TrainerWithEarlyStopping(\n            model=self.model,\n            loader_train=self.loader_train,\n            loader_test=self.loader_test,\n            loss_fn=self.loss_fn,\n            metric_fn=self.metric_fn,\n            optimizer=self.optimizer,\n            lr_scheduler=self.lr_scheduler,\n            device=device,\n            data_getter=itemgetter(0),\n            target_getter=itemgetter(1),\n            stage_progress=trainer_config.progress_bar,\n            get_key_metric=itemgetter(\"top1\"),\n            visualizer=self.visualizer,\n            model_saving_frequency=trainer_config.model_saving_frequency,\n            save_dir=trainer_config.model_dir\n        )\n\n        model_trainer.register_hook(\"end_epoch\", hooks.end_epoch_hook_classification)\n        model_trainer.register_hook(\"early_stop\", hooks.early_stop_hook_classification)\n        self.metrics = model_trainer.fit(trainer_config.epoch_num)\n        return self.metrics","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:17:12.022836Z","iopub.execute_input":"2022-01-01T01:17:12.023113Z","iopub.status.idle":"2022-01-01T01:17:12.037924Z","shell.execute_reply.started":"2022-01-01T01:17:12.023074Z","shell.execute_reply":"2022-01-01T01:17:12.037187Z"},"trusted":true},"execution_count":273,"outputs":[]},{"cell_type":"markdown","source":"Run the check experiment","metadata":{}},{"cell_type":"code","source":"check_experiment = CheckExperiment(system_config=check_system_config,\n                                   dataset_config=check_dataset_config,\n                                   dataloader_config=check_dataloader_config,\n                                   optimizer_config=check_optimizer_config)\ncheck_metrics = check_experiment.run(check_trainer_config)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:17:12.039251Z","iopub.execute_input":"2022-01-01T01:17:12.039585Z","iopub.status.idle":"2022-01-01T01:20:54.216496Z","shell.execute_reply.started":"2022-01-01T01:17:12.039546Z","shell.execute_reply":"2022-01-01T01:20:54.215625Z"},"trusted":true},"execution_count":274,"outputs":[]},{"cell_type":"markdown","source":"#### <font style=\"color:green\">1.1.5 Check Trained Model</font>","metadata":{"_uuid":"983a4192-f523-4ace-a6c1-df7db26a9be5","_cell_guid":"06a65058-1db7-478c-9db9-bb4f8be30d7d","trusted":true}},{"cell_type":"code","source":"def load_model(model, model_dir=check_trainer_config.model_dir):\n    list_of_files = glob.glob('{}/*'.format(model_dir))\n    latest_model_file = max(list_of_files, key=os.path.getctime)\n    \n    # loading the model and getting model parameters by using load_state_dict\n    model.load_state_dict(torch.load(latest_model_file))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:54.218301Z","iopub.execute_input":"2022-01-01T01:20:54.219045Z","iopub.status.idle":"2022-01-01T01:20:54.225782Z","shell.execute_reply.started":"2022-01-01T01:20:54.218998Z","shell.execute_reply":"2022-01-01T01:20:54.224875Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"model = load_model(ShrunkAlexNet(num_classes))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:54.227462Z","iopub.execute_input":"2022-01-01T01:20:54.227752Z","iopub.status.idle":"2022-01-01T01:20:54.462055Z","shell.execute_reply.started":"2022-01-01T01:20:54.227711Z","shell.execute_reply":"2022-01-01T01:20:54.461228Z"},"trusted":true},"execution_count":276,"outputs":[]},{"cell_type":"code","source":"check_metrics","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:54.465440Z","iopub.execute_input":"2022-01-01T01:20:54.471523Z","iopub.status.idle":"2022-01-01T01:20:54.483215Z","shell.execute_reply.started":"2022-01-01T01:20:54.471479Z","shell.execute_reply":"2022-01-01T01:20:54.482558Z"},"trusted":true},"execution_count":277,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(15, 5))\naxs[0].plot(check_metrics[\"test_loss\"])\naxs[0].set_title('Validation Loss')\naxs[0].set_xlabel('epoch')\nfig.suptitle('Check Results', fontsize=12)\n\naxs[1].plot(check_metrics[\"train_loss\"])\naxs[1].set_title('Train Loss')\naxs[1].set_xlabel('epoch')\n\naxs[2].plot([metric['top1'] for metric in check_metrics[\"test_metric\"]])\naxs[2].set_title('Accuracy')\naxs[2].set_xlabel('epoch')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:54.484659Z","iopub.execute_input":"2022-01-01T01:20:54.486516Z","iopub.status.idle":"2022-01-01T01:20:55.123974Z","shell.execute_reply.started":"2022-01-01T01:20:54.486473Z","shell.execute_reply":"2022-01-01T01:20:55.123086Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"markdown","source":"#### <font style=\"color:green\">1.1.6 Check Trained Model Prediction</font>","metadata":{"_uuid":"d158c2e8-1acd-4959-8636-c8c8ceb9fc29","_cell_guid":"9981a4e1-1212-4e60-94c4-df50223d8c99","trusted":true}},{"cell_type":"code","source":"def prediction(model, device, batch_input):\n    \n    # send model to cpu/cuda according to your system configuration\n    model.to(device)\n    \n    # it is important to do model.eval() before prediction\n    model.eval()\n\n    data = batch_input.to(device)\n\n    output = model(data)\n\n    # Score to probability using softmax\n    prob = F.softmax(output, dim=1)\n\n    # get the max probability\n    pred_prob = prob.data.max(dim=1)[0]\n    \n    # get the index of the max probability\n    pred_index = prob.data.max(dim=1)[1]\n    \n    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:55.128754Z","iopub.execute_input":"2022-01-01T01:20:55.131330Z","iopub.status.idle":"2022-01-01T01:20:55.143100Z","shell.execute_reply.started":"2022-01-01T01:20:55.131233Z","shell.execute_reply":"2022-01-01T01:20:55.142019Z"},"trusted":true},"execution_count":279,"outputs":[]},{"cell_type":"code","source":"def get_sample_prediction(model, data_root, mean, std):\n    batch_size = 15\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    num_workers = 2\n        \n    \n    # transformed data\n    test_dataset_trans = KenyanFood13Dataset(data_root=data_root, train=False, transform=image_common_transforms(mean, std))\n    # original image dataset\n    test_dataset = KenyanFood13Dataset(data_root=data_root, train=False, transform=image_preprocess_transforms())\n    \n    data_len = test_dataset.__len__()\n    \n    interval = int(data_len/batch_size)\n    \n    imgs = []\n    inputs = []\n    targets = []\n    for i in range(batch_size):\n        index = i * interval\n        trans_input, target = test_dataset_trans.__getitem__(index)\n        img, _ = test_dataset.__getitem__(index)\n        \n        imgs.append(img)\n        inputs.append(trans_input)\n        targets.append(target)\n        \n    inputs = torch.stack(inputs)\n        \n    cls, prob = prediction(model, device, batch_input=inputs)\n    \n    plt.style.use('default')\n    plt.rcParams[\"figure.figsize\"] = (20, 15)\n    fig = plt.figure()\n    \n    \n    for i, target in enumerate(targets):\n        plt.subplot(3, 5, i+1)\n        img = transforms.functional.to_pil_image(imgs[i])\n        plt.imshow(img)\n        plt.gca().set_title('P:{0}({1:.2}), T:{2}'.format(test_dataset.classes[cls[i]], \n                                                     prob[i], \n                                                     test_dataset.classes[targets[i]]))\n    fig.savefig('check_sample_prediction.png')\n    plt.show()\n    \n    return","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:55.145245Z","iopub.execute_input":"2022-01-01T01:20:55.146124Z","iopub.status.idle":"2022-01-01T01:20:55.172998Z","shell.execute_reply.started":"2022-01-01T01:20:55.146079Z","shell.execute_reply":"2022-01-01T01:20:55.171854Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"get_sample_prediction(model, data_root, mean, std)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:55.179261Z","iopub.execute_input":"2022-01-01T01:20:55.182432Z","iopub.status.idle":"2022-01-01T01:20:59.673097Z","shell.execute_reply.started":"2022-01-01T01:20:55.182371Z","shell.execute_reply":"2022-01-01T01:20:59.672448Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"def get_wrong_prediction(model, data_root, mean, std):\n    # Sample twice the images of the previous function...\n    batch_size = 32\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    num_workers = 2\n        \n    \n    # transformed data\n    test_dataset_trans = KenyanFood13Dataset(data_root=data_root, train=False, transform=image_common_transforms(mean, std))\n    # original image dataset\n    test_dataset = KenyanFood13Dataset(data_root=data_root, train=False, transform=image_preprocess_transforms())\n    \n    data_len = test_dataset.__len__()\n    \n    interval = int(data_len/batch_size)\n    \n    imgs = []\n    inputs = []\n    targets = []\n    for i in range(batch_size):\n        # ... adjusting the index for the right amount of misclassified examples,...\n        index = i * interval + 3\n        trans_input, target = test_dataset_trans.__getitem__(index)\n        img, _ = test_dataset.__getitem__(index)\n        imgs.append(img)\n        inputs.append(trans_input)\n        targets.append(target)\n        \n    inputs = torch.stack(inputs)\n    \n    cls, prob = prediction(model, device, batch_input=inputs)\n    \n    plt.style.use('default')\n    plt.rcParams[\"figure.figsize\"] = (20, 15)\n    fig = plt.figure()\n    \n    i = 0\n    j = 0\n    while i < len(targets) and j < 15:\n        # ... and then print only the misclassified ones\n        if test_dataset.classes[cls[i]] != test_dataset.classes[targets[i]]:\n            j += 1\n            plt.subplot(3, 5, j)\n            img = transforms.functional.to_pil_image(imgs[i])\n            plt.imshow(img)\n            plt.gca().set_title('P:{0}({1:.2}), T:{2}'.format(test_dataset.classes[cls[i]], \n                                                     prob[i], \n                                                     test_dataset.classes[targets[i]]))\n        i = i + 1\n            \n    fig.savefig('check_wrong_prediction.png')\n    plt.show()\n    \n    return","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:59.674484Z","iopub.execute_input":"2022-01-01T01:20:59.674837Z","iopub.status.idle":"2022-01-01T01:20:59.689879Z","shell.execute_reply.started":"2022-01-01T01:20:59.674804Z","shell.execute_reply":"2022-01-01T01:20:59.689274Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"get_wrong_prediction(model, data_root, mean, std)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:20:59.691312Z","iopub.execute_input":"2022-01-01T01:20:59.691815Z","iopub.status.idle":"2022-01-01T01:21:04.905801Z","shell.execute_reply.started":"2022-01-01T01:20:59.691779Z","shell.execute_reply":"2022-01-01T01:21:04.903449Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"# Free memory and reset values\n%xdel train_data\n%xdel validation_data\n%xdel subset_size\n%xdel show_subset\n%xdel train_subset\n%xdel check_system_config\n%xdel mean\n%xdel std\n%xdel train_validation_transforms\n%xdel check_dataset_config\n%xdel check_dataloader_config\n%xdel check_optimizer_config\n%xdel check_trainer_config\n%xdel x\n%xdel target\n%xdel criterion\n%xdel optimizer\n%xdel loss_list\n%xdel num_epochs\n%xdel per_epoch_loss\n%xdel model_overfit\n%xdel check_experiment\n%xdel check_metrics\n%xdel model","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-01T01:21:04.907256Z","iopub.execute_input":"2022-01-01T01:21:04.907705Z","iopub.status.idle":"2022-01-01T01:21:05.021015Z","shell.execute_reply.started":"2022-01-01T01:21:04.907666Z","shell.execute_reply":"2022-01-01T01:21:05.020003Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">2. Configuration [5 Points]</font>\n\n**Define your configuration here.**\n\nFor example:\n\n\n```python\n@dataclass\nclass TrainingConfiguration:\n    '''\n    Describes configuration of the training process\n    '''\n    batch_size: int = 10 \n    epochs_count: int = 50  \n    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n    log_interval: int = 5  \n    test_interval: int = 1  \n    data_root: str = \"/kaggle/input/pytorch-opencv-course-classification/\" \n    num_workers: int = 2  \n    device: str = 'cuda'  \n    \n```","metadata":{"_uuid":"dbec5d12-4457-477d-8515-7292ed1284a4","_cell_guid":"6bbb81eb-8542-44c4-941f-bb7ff03495d8","trusted":true}},{"cell_type":"markdown","source":"Already defined in the `trainer` package. For reference:\n\n```python\n@dataclass\nclass SystemConfig:\n    seed: int = 41  # seed number to set the state of all random number generators\n    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)\n\n@dataclass\nclass DatasetConfig:\n    root_dir: str = \"data\"  # dataset directory root\n    train_transforms: Iterable[Callable] = (\n        ToTensor(),\n    )  # data transformation to use during training data preparation\n    test_transforms: Iterable[Callable] = (\n        ToTensor(),\n    )  # data transformation to use during test data preparation\n\n@dataclass\nclass DataloaderConfig:\n    batch_size: int = 250  # amount of data to pass through the network at each forward-backward iteration\n    num_workers: int = 5  # number of concurrent processes using to prepare data\n\n@dataclass\nclass OptimizerConfig:\n    learning_rate: float = 0.001  # determines the speed of network's weights update\n    momentum: float = 0.9  # used to improve vanilla SGD algorithm and provide better handling of local minimas\n    weight_decay: float = 0.0001  # amount of additional regularization on the weights values\n    lr_step_milestones: Iterable = (\n        30, 40\n    )  # at which epoches should we make a \"step\" in learning rate (i.e. decrease it in some manner)\n    lr_gamma: float = 0.1  # multiplier applied to current learning rate at each of lr_ctep_milestones\n\n@dataclass\nclass TrainerConfig:\n    model_dir: str = \"checkpoints\"  # directory to save model states\n    model_saving_frequency: int = 1  # frequency of model state savings per epochs\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # device to use for training.\n    epoch_num: int = 50  # number of times the whole dataset will be passed through the network\n    progress_bar: bool = True  # enable progress bar visualization during train process\n```\n\nSome of theese configuration will be overridden later.","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n\n**Define methods or classes that will be used in model evaluation. For example, accuracy, f1-score etc.**","metadata":{"_uuid":"91797be0-1cc3-4839-beca-3fcc38fc9949","_cell_guid":"8c7ccd1a-f220-483b-856d-0ccde06e96af","trusted":true}},{"cell_type":"markdown","source":"Accuracy, train loss and test loss are included in the `trainer` package.","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n\n\n**Write the methods or classes to be used for training and validation.**","metadata":{"_uuid":"ffe13b2e-f0dd-41d6-8111-639071bb2c34","_cell_guid":"08bbbd95-edc6-4240-95ff-ceef1ce8bdaa","trusted":true}},{"cell_type":"markdown","source":"The train and validate loop are included in the `trainer` package.","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">5. Model [5 Points]</font>\n\n**Define your model in this section.**\n\n**You are allowed to use any pre-trained model.**","metadata":{"_uuid":"8dfbec53-2018-4bb8-9cd2-d4919a9db824","_cell_guid":"a139d838-f734-4c0e-8f27-3e3de74e619f","trusted":true}},{"cell_type":"code","source":"def pretrained_resnet18(num_class=num_classes, finetune=True, freeze_first : int=3):\n    resnet = models.resnet18(pretrained=True)\n    \n    # Trainable layer names\n    trainable_layer_names = [\"conv1\", \"bn1\", \"layer1\", \"layer2\", \"layer3\", \"layer4\"]\n    if finetune:\n        freeze_first = min(max(2, freeze_first), len(trainable_layer_names))\n        for layer_name in trainable_layer_names[:freeze_first]:\n            for param in getattr(resnet, layer_name).parameters():\n                param.requires_grad = False\n    else:\n        for param in resnet.parameters():\n            param.requires_grad = False\n            \n    last_layer_in = resnet.fc.in_features\n    resnet.fc = nn.Linear(last_layer_in, num_class, bias=False)  # requires_grad = True\n    \n    return resnet","metadata":{"_uuid":"fb556aab-4f84-4948-b1ee-aca15dc143c5","_cell_guid":"42712d78-9d2e-4280-9f62-b090ec8d253b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-01T01:21:05.022776Z","iopub.execute_input":"2022-01-01T01:21:05.023204Z","iopub.status.idle":"2022-01-01T01:21:05.032608Z","shell.execute_reply.started":"2022-01-01T01:21:05.023064Z","shell.execute_reply":"2022-01-01T01:21:05.031738Z"},"trusted":true},"execution_count":285,"outputs":[]},{"cell_type":"code","source":"resnet18_finetune = pretrained_resnet18()\n# print({n: [(nn, p.requires_grad) for nn, p in l.named_parameters()] for n, l in resnet18_finetune.named_children()})\nprint(resnet18_finetune)","metadata":{"_uuid":"a31d33c4-ff38-4c24-9eaa-e76ae08deb83","_cell_guid":"2b6ffe1e-f2cd-48b1-984d-1ee774ea7b3b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-01T01:21:05.033896Z","iopub.execute_input":"2022-01-01T01:21:05.034241Z","iopub.status.idle":"2022-01-01T01:21:05.564215Z","shell.execute_reply.started":"2022-01-01T01:21:05.034198Z","shell.execute_reply":"2022-01-01T01:21:05.563438Z"},"trusted":true},"execution_count":286,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">6. Utils [5 Points]</font>\n\n**Define those methods or classes, which have  not been covered in the above sections.**","metadata":{"_uuid":"5a60b6c7-30bf-4e5e-bfa7-a25d403b65ae","_cell_guid":"c7b23368-2a41-4164-82ca-d5eec00fa141","trusted":true}},{"cell_type":"code","source":"def prediction(model, device, batch_input):\n    \n    # send model to cpu/cuda according to your system configuration\n    model.to(device)\n    \n    # it is important to do model.eval() before prediction\n    model.eval()\n\n    data = batch_input.to(device)\n\n    output = model(data)\n\n    # Score to probability using softmax\n    prob = F.softmax(output, dim=1)\n\n    # get the max probability\n    pred_prob = prob.data.max(dim=1)[0]\n    \n    # get the index of the max probability\n    pred_index = prob.data.max(dim=1)[1]\n    \n    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T01:21:05.565703Z","iopub.execute_input":"2022-01-01T01:21:05.566164Z","iopub.status.idle":"2022-01-01T01:21:05.573043Z","shell.execute_reply.started":"2022-01-01T01:21:05.566123Z","shell.execute_reply":"2022-01-01T01:21:05.572311Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">7. Experiment [5 Points]</font>\n\n**Choose your optimizer and LR-scheduler and use the above methods and classes to train your model.**","metadata":{"_uuid":"74b4b9ea-8f1d-4948-bbb5-15f383bdb3ac","_cell_guid":"512045be-0536-4135-b73f-c9f3b1be0353","trusted":true}},{"cell_type":"code","source":"class Experiment:\n    def __init__(\n        self,\n        system_config: configuration.SystemConfig = configuration.SystemConfig(),\n        dataset_config: configuration.DatasetConfig = configuration.DatasetConfig(),\n        dataloader_config: configuration.DataloaderConfig = configuration.DataloaderConfig(),\n        optimizer_config: configuration.OptimizerConfig = configuration.OptimizerConfig()\n    ):\n        self.loader_train, self.loader_test = get_data(\n            batch_size=dataloader_config.batch_size,\n            data_root=dataset_config.root_dir,\n            num_workers=dataloader_config.num_workers\n        )\n        \n        setup_system(system_config)\n\n        self.model = resnet18_finetune\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.metric_fn = AccuracyEstimator(topk=(1, ))\n        self.optimizer = optim.SGD(\n            self.model.parameters(),\n            lr=optimizer_config.learning_rate,\n            weight_decay=optimizer_config.weight_decay,\n            momentum=optimizer_config.momentum\n        )\n        self.lr_scheduler = MultiStepLR(\n            self.optimizer,\n            milestones=optimizer_config.lr_step_milestones,\n            gamma=optimizer_config.lr_gamma\n        )\n        self.visualizer = TensorBoardVisualizer()\n\n    def run(self, trainer_config: configuration.TrainerConfig) -> dict:\n\n        # device = torch.device(trainer_config.device)\n        device = \"cuda\" if torch.cuda.is_available() else trainer_config.device\n        self.model = self.model.to(device)\n        self.loss_fn = self.loss_fn.to(device)\n\n        model_trainer = Trainer(\n            model=self.model,\n            loader_train=self.loader_train,\n            loader_test=self.loader_test,\n            loss_fn=self.loss_fn,\n            metric_fn=self.metric_fn,\n            optimizer=self.optimizer,\n            lr_scheduler=self.lr_scheduler,\n            device=device,\n            data_getter=itemgetter(0),\n            target_getter=itemgetter(1),\n            stage_progress=trainer_config.progress_bar,\n            get_key_metric=itemgetter(\"top1\"),\n            visualizer=self.visualizer,\n            model_saving_frequency=trainer_config.model_saving_frequency,\n            save_dir=trainer_config.model_dir\n        )\n\n        model_trainer.register_hook(\"end_epoch\", hooks.end_epoch_hook_classification)\n        self.metrics = model_trainer.fit(trainer_config.epoch_num)\n        return self.metrics, self.model","metadata":{"_uuid":"53c608fa-800c-43fa-81c2-eba039348ade","_cell_guid":"9531a76f-0ebc-4c5e-bffe-d35b88bf1467","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-01T01:21:05.574787Z","iopub.execute_input":"2022-01-01T01:21:05.575683Z","iopub.status.idle":"2022-01-01T01:21:05.590227Z","shell.execute_reply.started":"2022-01-01T01:21:05.575643Z","shell.execute_reply":"2022-01-01T01:21:05.589524Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"dataset_config = configuration.DatasetConfig(root_dir=data_root)\ndataloader_config, trainer_config = patch_configs(epoch_num_to_set=9,\n                                                  batch_size_to_set=64 if torch.cuda.is_available() else 16)\noptimizer_config = configuration.OptimizerConfig(learning_rate=1e-3,\n                                                 lr_step_milestones=(5, ))\nexperiment = Experiment(dataset_config=dataset_config,\n                        dataloader_config=dataloader_config,\n                        optimizer_config=optimizer_config)\nmetrics, model = experiment.run(trainer_config)","metadata":{"_uuid":"a9fb0ad2-b351-41aa-bc56-d05c1d9537e2","_cell_guid":"edc1d655-dba8-48a6-bc58-32b88b7a4c0d","execution":{"iopub.status.busy":"2022-01-01T01:21:05.591623Z","iopub.execute_input":"2022-01-01T01:21:05.592536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(15, 5))\naxs[0].plot(metrics[\"test_loss\"])\naxs[0].set_title('Validation Loss')\naxs[0].set_xlabel('epoch')\nfig.suptitle('Experiments Results', fontsize=12)\n\naxs[1].plot(metrics[\"train_loss\"])\naxs[1].set_title('Train Loss')\naxs[1].set_xlabel('epoch')\n\naxs[2].plot([metric['top1'] for metric in metrics[\"test_metric\"]])\naxs[2].set_title('Accuracy')\naxs[2].set_xlabel('epoch')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">8. TensorBoard Dev Scalars Log Link [5 Points]</font>\n\n**Share your TensorBoard scalars logs link here. You can also share (not mandatory) your GitHub link, if you have pushed this project in GitHub.**\n\n\nFor example, [Find Project2 logs here](https://tensorboard.dev/experiment/kMJ4YU0wSNG0IkjrluQ5Dg/#scalars).","metadata":{"_uuid":"4ed2882f-8ca9-4337-9309-ccd538f298be","_cell_guid":"b18be049-9543-42b3-b183-5a5224255f68","trusted":true}},{"cell_type":"code","source":"%reload_ext tensorboard","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %tensorboard dev upload --logdir logs_ap_project_2/ --name \"Aureliano Porporato Project 2 Experiment\" --description \"Aureliano Porporato \\\"Deep Learning with Pytorch\\\" Project 2\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tensorboard.dev logs for the project can be found [here]().\\\nThe notebook has been uploaded to GitHub [here](https://github.com/aporporato/ap-opencv-course-3-project-2/blob/main/aureliano-porporato-project-2-notebook.ipynb).","metadata":{"_uuid":"64532aaf-ad08-44d7-95f8-3b1648d1e4c0","_cell_guid":"c90fd586-5f26-44f1-bd71-c1075dde29b2","trusted":true}},{"cell_type":"markdown","source":"## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n\n**Share your Kaggle profile link  with us here to score points in  the competition.**\n\n**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n\n\n**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, to get evaluated for  this section.**","metadata":{"_uuid":"80b81f0e-9ff3-40b6-9063-a161822814a9","_cell_guid":"93e6e3a9-5d58-45bb-8397-c506b4a0e269","trusted":true}},{"cell_type":"code","source":"class KenyanFood13Testset(Dataset):\n    \"\"\"\n    Kenyan Food unlabel Testset, from Kaggle, for the Project 2 of Deep Learning with Pytorch (by OpenCV.org)\n    \"\"\"\n    \n    def __init__(self, data_root, idx2class, class2idx, image_shape=None, transform=None):\n        \n        \"\"\"\n        init method of the class.\n        \n         Parameters:\n         \n         data_root (string): path of root directory.\n         \n         image_shape (int or tuple or list): [optional] int or tuple or list. Defaut is None. \n                                             It is not None image will resize to the given shape.\n                                 \n         transform (method): method that will take PIL image and transforms it.\n         \n        \"\"\"\n        \n        label_less_csv_path = os.path.join(data_root, 'test.csv')\n        \n        self.testset = pd.read_csv(label_less_csv_path)\n        \n        self.idx2class = idx2class\n        self.class2idx = class2idx\n        \n        # set image_resize attribute\n        if image_shape is not None:\n            if isinstance(image_shape, int):\n                self.image_shape = (image_shape, image_shape)\n            \n            elif isinstance(image_shape, tuple) or isinstance(image_shape, list):\n                assert len(image_shape) == 1 or len(image_shape) == 2, 'Invalid image_shape tuple size'\n                if len(image_shape) == 1:\n                    self.image_shape = (image_shape[0], image_shape[0])\n                else:\n                    self.image_shape = image_shape\n            else:\n                raise NotImplementedError \n        else:\n            self.image_shape = None\n            \n        # set transform attribute\n        self.transform = transform\n                \n        self.num_classes = num_classes\n        \n        self.data_dict = {\n            'image_path': [],\n            'image_name': []\n        }\n        \n        dir_path = os.path.join(data_root, 'images', 'images')\n\n        for _, image in self.testset.iterrows():\n            image_name = image[0]\n            image_path = os.path.join(dir_path, '{}.jpg'.format(image_name))\n            self.data_dict['image_path'].append(image_path)\n            self.data_dict['image_name'].append(image_name)\n            \n    def get_test(self):\n        return self.data_dict\n                    \n                \n    def __len__(self):\n        \"\"\"\n        Return length of the dataset\n        \"\"\"\n        \n        return len(self.data_dict['image_name'])\n    \n    \n    def __getitem__(self, idx):\n        \"\"\"\n        For given index, return images with resize and preprocessing.\n        \"\"\"\n        \n        image = Image.open(self.data_dict['image_path'][int(idx)]).convert(\"RGB\")\n        \n        if self.image_shape is not None:\n            image = FF.resize(image, self.image_shape)\n            \n        if self.transform is not None:\n            image = self.transform(image)\n        \n        return image, self.num_classes\n    \n    \n    def create_submission(self, predictions):\n        \"\"\"\n        Prepare CSV file for submission.\n        \"\"\"\n        labels = [self.idx2class[p] for p in predictions]\n        submission_df = pd.DataFrame(list(zip(self.data_dict['image_name'], labels)), columns=['id', 'class'])\n        submission_df.to_csv(\"./submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean, std = get_resnet_mean_std()\ntest_transform = image_common_transforms(mean, std)\ntest_set = KenyanFood13Testset(data_root, idx2class, class2idx,\n                               image_shape=None,\n                               transform=test_transform)\ntest_loader = torch.utils.data.DataLoader(test_set,\n                                          batch_size=64 if torch.cuda.is_available() else 8,\n                                          num_workers=2,\n                                          shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.array([])\nfor data, _ in test_loader:\n    p, _ = prediction(model, \"cuda\" if torch.cuda.is_available() else \"cpu\", data)\n    preds = np.concatenate((preds, p), axis=None)\n    \n\ntest_set.create_submission(preds)\nprint(\"File created\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}